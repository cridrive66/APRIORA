# -*- coding: utf-8 -*-

"""
/***************************************************************************
 APRIORA
                                 A QGIS plugin
 Collection of APRIORA Plugins
 Generated by Plugin Builder: http://g-sherman.github.io/Qgis-Plugin-Builder/
                              -------------------
        begin                : 2024-06-13
        copyright            : (C) 2024 by Universität Rostock
        email                : cristiano.guidi2@uni-rostock.de
 ***************************************************************************/

/***************************************************************************
 *                                                                         *
 *   This program is free software; you can redistribute it and/or modify  *
 *   it under the terms of the GNU General Public License as published by  *
 *   the Free Software Foundation; either version 2 of the License, or     *
 *   (at your option) any later version.                                   *
 *                                                                         *
 ***************************************************************************/
"""

__author__ = 'Universität Rostock'
__date__ = '2024-06-13'
__copyright__ = '(C) 2024 by Universität Rostock'

# This will get replaced with a git SHA1 when you do a git archive

__revision__ = '$Format:%H$'

import os
import math

import geopandas as gpd
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

from osgeo import gdal
from processing.gui.wrappers import WidgetWrapper
from qgis.PyQt.QtWidgets import QListWidget, QListWidgetItem
from PyQt5.QtCore import QVariant
from qgis import processing
from qgis.PyQt.QtCore import QCoreApplication, Qt, QDir
from qgis.core import (QgsProcessing,
                       QgsProcessingParameterVectorDestination,
                       QgsVectorFileWriter,
                       QgsFeature,
                       QgsFields,
                       QgsFeatureSink,
                       QgsProcessingAlgorithm,
                       QgsProcessingParameterFile,
                       QgsProcessingParameterFeatureSource,
                       QgsProcessingParameterFeatureSink,
                       QgsProcessingParameterBoolean,
                       QgsProcessingParameterMatrix,
                       QgsProcessingParameterRasterLayer,
                       QgsProcessingParameterFolderDestination,
                       QgsField,
                       QgsVectorLayer,
                       QgsRasterLayer,
                       QgsProject,
                       QgsRasterBandStats)
    
"""
class PickOptionWidget(WidgetWrapper):

    def createWidget(self):
        self._combo = QListWidget()
        #item1 = QListWidgetItem("Subcatchment statistics")
        item2 = QListWidgetItem("Water statistics")
        item3 = QListWidgetItem("Forest share")
        item4 = QListWidgetItem("Settlement share")
        item5 = QListWidgetItem("Precipitation statistics")
        item7 = QListWidgetItem("Percentage of permeable soil")
        item8 = QListWidgetItem("Distance from groundwater level")
        #item1.setCheckState(Qt.Checked)
        item2.setCheckState(Qt.Checked)
        item3.setCheckState(Qt.Checked)
        item4.setCheckState(Qt.Checked)
        item5.setCheckState(Qt.Checked)
        item7.setCheckState(Qt.Checked)
        item8.setCheckState(Qt.Checked)
        #self._combo.addItem(item1)
        self._combo.addItem(item2)
        self._combo.addItem(item3)
        self._combo.addItem(item4)
        self._combo.addItem(item5)
        self._combo.addItem(item7)
        self._combo.addItem(item8)

        return self._combo

    def value(self):
        chosen = []
        for i in range(self._combo.count()):
            if self._combo.item(i).checkState() == Qt.Checked:
                chosen.append(self._combo.item(i).text())

        return chosen
"""

class CalculateGeofactors(QgsProcessingAlgorithm):

    # Constants used to refer to parameters and outputs. They will be
    # used when calling the algorithm from another algorithm, or when
    # calling from the QGIS console.

    OUTPUT = 'OUTPUT'
    catchmentAreas = 'CatchmentAreas'
    DGM = 'DGM'
    slopeRaster = 'SlopeRaster'
    chosenGeofactors = 'ChosenGeofactors'
    waterArea  = 'WaterArea'
    riverNetwork = 'RiverNetwork'
    forestArea = 'ForestArea'
    settlementArea = 'SettlementArea'
    precipitationData = 'PrecipitationData'
    

    #Init tool
    def initAlgorithm(self, config):
        """
        Here we define the inputs and output of the algorithm, along
        with some other properties.
        """
        self.addParameter(
            QgsProcessingParameterFeatureSource(
                self.catchmentAreas,
                self.tr('Catchment areas'),
                [QgsProcessing.TypeVectorPolygon]
            )
        )
        
        self.addParameter(
            QgsProcessingParameterRasterLayer(
                self.DGM,
                self.tr('Digital surface model'),
                [QgsProcessing.TypeRaster]
            )
        )
        
        self.addParameter(
            QgsProcessingParameterRasterLayer(
                self.slopeRaster,
                self.tr('Slope raster'),
                [QgsProcessing.TypeRaster] 
            )
        )
        
        self.addParameter(
            QgsProcessingParameterFeatureSource(
                self.riverNetwork,
                self.tr('River network'),
                [QgsProcessing.TypeVectorLine]
            )
        )
        
        self.addParameter(
            QgsProcessingParameterFeatureSource(
                self.waterArea,
                self.tr('Water area'),
                [QgsProcessing.TypeVectorPolygon]
            )
        )
        
        self.addParameter(
            QgsProcessingParameterFeatureSource(
                self.forestArea,
                self.tr('Forest area'),
                [QgsProcessing.TypeVectorPolygon]
            )
        )
        
        self.addParameter(
            QgsProcessingParameterFeatureSource(
                self.settlementArea,
                self.tr('Settlement area'),
                [QgsProcessing.TypeVectorPolygon]
            )
        )

                
        self.addParameter(
            QgsProcessingParameterFile(
                self.precipitationData,
                self.tr('Precipitation data (folder)'),
                behavior=QgsProcessingParameterFile.Folder
            )
        )
        
        
        """
        file_param = QgsProcessingParameterMatrix(self.chosenGeofactors, 'Select geofactor')
        file_param.setMetadata({'widget_wrapper': {'class': PickOptionWidget}})
        self.addParameter(file_param)
        """
        
        # We add a feature sink in which to store our processed features (this
        # usually takes the form of a newly created vector layer when the
        # algorithm is run in QGIS).
        self.addParameter(
            QgsProcessingParameterFeatureSink(
                self.OUTPUT,
                self.tr('Output layer'),
                QgsProcessing.TypeVectorPolygon
            )
        )
    
    def createRaster(self, parameters, context, feedback, outfn, xmax, xmin, xres, ymax, ymin, yres, spatref, raster):
        #create Raster
        driver = gdal.GetDriverByName('GTiff')
        wkt = spatref.toWkt()
        nbands = 1
        nodata = -999
        dtype = gdal.GDT_Float32
        xsize = abs(int((xmax - xmin) / xres))
        ysize = abs(int((ymax - ymin) / yres))
        ds = driver.Create(outfn, xsize, ysize, nbands, dtype)
        ds.GetRasterBand(1).WriteArray(raster)
        ds.SetProjection(wkt)
        ds.SetGeoTransform([xmin, xres, 0, ymax, 0, -yres])
        ds.GetRasterBand(1).SetNoDataValue(nodata)
        ds.FlushCache()
        ds = None    
        
    def processPropotions(self, parameters, context, feedback, catchments, outputDir, fileName, fieldName, target, calcOption):
        #Calculates intersection of subcatchments and area/length
        feedback.setProgressText("\nCalculate statistics based on "+ fileName +"...")
        algresultIntersection = processing.run("native:intersection",
            {'INPUT': target,
             'OVERLAY':catchments,
             'OVERLAY_FIELDS': 'ID_SC',
             'OVERLAY_FIELDS_PREFIX': "",
             'OUTPUT': 'TEMPORARY_OUTPUT'},
            context=context, feedback=feedback)
        intersections = algresultIntersection['OUTPUT']

        #Calculates area/length of target parts
        provider = intersections.dataProvider()
        field = QgsField(fieldName+"_SC", QVariant.Double, 'double', 20, 3)
        provider.addAttributes([field])
        intersections.updateFields() 
        idx = provider.fieldNameIndex(fieldName+"_SC")
        for feature in intersections.getFeatures():
            if calcOption == 0: #0=area; 1=length/perimeter
                geom = feature.geometry().area()
            else:
                geom = feature.geometry().length()
            attrs = {idx : geom}
            intersections.dataProvider().changeAttributeValues({feature.id() : attrs})

        
        #Summarizes the target field based on the ID_SC field
        algresultSummarize = processing.run("qgis:statisticsbycategories",
            {'INPUT': intersections,
             'VALUES_FIELD_NAME':fieldName+"_SC",
             'CATEGORIES_FIELD_NAME': 'ID_SC',
             'OUTPUT': 'TEMPORARY_OUTPUT'},
            context=context, feedback=feedback)
        Summarize = algresultSummarize['OUTPUT']
        
        #Joins the sum of area information to catchments
        algresultJoinCatchmentsSummarize = processing.run("qgis:joinattributestable",
            {'INPUT': catchments,
             'FIELD':'ID_SC',
             'INPUT_2': Summarize,
             'FIELD_2': 'ID_SC',
             'FIELDS_TO_COPY': 'sum',
             'METHOD': 1,
             'DISCARD_NONMATCHING': False,
             'PREFIX': fieldName+'_',
             'OUTPUT': 'TEMPORARY_OUTPUT'},
            context=context, feedback=feedback)
        JoinCatchmentsSummarize = algresultJoinCatchmentsSummarize['OUTPUT']
        del intersections
        return JoinCatchmentsSummarize

    def processAlgorithm(self, parameters, context, feedback):
        """
        Here is where the processing itself takes place.
        """
        #Get data
        #parameterList = self.parameterAsMatrix(parameters, self.chosenGeofactors, context)
        catchmentSource = self.parameterAsVectorLayer(parameters, 'CatchmentAreas', context)
        catchmentSourceName = catchmentSource.name()
        
        #Get virtual output directory and output sink
        outputDir = "/vsimem/"
        


        #List of Outputs
        results = []
        #Start chosen calculations (parallelize if necessary)
        
        #Calculates zonal statistics based on DEM
        feedback.setProgressText("\nCalculate Zonal statistics...")
        algresultZonalStats = processing.run("native:zonalstatisticsfb",
            {'INPUT_RASTER': parameters[self.DGM],
             'RASTER_BAND':1,
             'INPUT': parameters[self.catchmentAreas],
             'COLUMN_PREFIX': "H_",
             'STATISTICS': [3, 4, 5],
             'OUTPUT': 'TEMPORARY_OUTPUT'},
            context=context, feedback=feedback)
        catchments = algresultZonalStats['OUTPUT']

        #Set area and perimeter field to layer
        provider = catchments.dataProvider()
        id_field = QgsField("ID_SC", QVariant.Int, 'int')
        area_field = QgsField("AREA_SC", QVariant.Double, 'double', 20, 3)
        perimeter_field = QgsField("PERI_SC", QVariant.Double, 'double', 20, 3)
        shapeFactor_field = QgsField("SHAPE_SC", QVariant.Double, 'double', 20, 3)
        provider.addAttributes([id_field, area_field, perimeter_field, shapeFactor_field])
        catchments.updateFields() 
        #Calculate area and perimeter
        idxID = provider.fieldNameIndex('ID_SC')
        idxArea = provider.fieldNameIndex('AREA_SC')
        idxPerimeter = provider.fieldNameIndex('PERI_SC')
        idxShapeFactor = provider.fieldNameIndex('SHAPE_SC')
        for feature in catchments.getFeatures():
            attrsID = {idxID : feature.id()}
            catchments.dataProvider().changeAttributeValues({feature.id() : attrsID})
            geomArea = feature.geometry().area()
            attrsArea = {idxArea : geomArea}
            catchments.dataProvider().changeAttributeValues({feature.id() : attrsArea})
            geomPeri = feature.geometry().length()
            attrsPerimeter = {idxPerimeter : geomPeri}
            catchments.dataProvider().changeAttributeValues({feature.id() : attrsPerimeter})
            geomShapeFactor =  math.pow(geomPeri, 2)/(2*math.pi*geomArea)
            attrsShapeFactor = {idxShapeFactor : geomShapeFactor}
            catchments.dataProvider().changeAttributeValues({feature.id() : attrsShapeFactor})

        slope = parameters[self.slopeRaster]

        #Calculates zonal statistics based on the slope raster 
        feedback.setProgressText("\nCalculate slope statistics...")
        processing.run("native:zonalstatistics",
            {'INPUT_RASTER': slope,
             'RASTER_BAND':1,
             'INPUT_VECTOR': catchments,
             'COLUMN_PREFIX': "S_",
             'STATISTICS': [3, 4]},
            context=context, feedback=feedback)
        results.extend([slope, catchments])

        #Calculates statistics based on river network
        JoinCatchmentsRiverSummarize = self.processPropotions(parameters, context, feedback, catchments, outputDir, "RiverNetwork", "RN", parameters[self.riverNetwork],1)

        #Calculates statistics based on water area
        JoinCatchmentsWaterAreaSummarize = self.processPropotions(parameters, context, feedback, JoinCatchmentsRiverSummarize, outputDir, "WaterArea", "WA", parameters[self.waterArea],0)
        
        #Calculates statistics based on forest area
        JoinCatchmentsForestAreaSummarize = self.processPropotions(parameters, context, feedback, JoinCatchmentsWaterAreaSummarize, outputDir, "ForestArea", "FA", parameters[self.forestArea],0)
        
        #Calculates statistics based on settlement area
        JoinCatchmentsSetttlementAreaSummarize = self.processPropotions(parameters, context, feedback, JoinCatchmentsForestAreaSummarize, outputDir, "SetttlementArea", "SA", parameters[self.settlementArea],0)
        
         #Calculates river network density (rnd), proportion of water area (pwa), forest share and settlemet share
        feedback.setProgressText("\nCalculate river network density (rnd) and Proportion of water area (pwa)...")
        provider = JoinCatchmentsSetttlementAreaSummarize.dataProvider()
        rnd_field = QgsField("RND", QVariant.Double, 'double', 20, 3)
        pwa_field = QgsField("PWA", QVariant.Double, 'double', 20, 3)
        fs_field = QgsField("FS", QVariant.Double, 'double', 20, 3)
        ss_field = QgsField("SS", QVariant.Double, 'double', 20, 3)
        provider.addAttributes([rnd_field, pwa_field, fs_field, ss_field])
        JoinCatchmentsSetttlementAreaSummarize.updateFields() 
        idxRND = provider.fieldNameIndex('RND')
        idxPWA = provider.fieldNameIndex('PWA')
        idxFS = provider.fieldNameIndex('FS')
        idxSS = provider.fieldNameIndex('SS')
        idxRN_Sum = provider.fieldNameIndex('RN_sum')
        idxWA_Sum = provider.fieldNameIndex('WA_sum')
        idxFA_Sum = provider.fieldNameIndex('FA_sum')
        idxSA_Sum = provider.fieldNameIndex('SA_sum')
        for feature in JoinCatchmentsSetttlementAreaSummarize.getFeatures():
            if feature["RN_sum"] != None:
                calcRND = (feature["RN_sum"] / feature["AREA_SC"]) *100
                RNsum = feature["RN_sum"]
            else:
                calcRND = 0
                RNsum = 0
            if feature["WA_sum"] != None:
                calcPWA = (feature["WA_sum"] / feature["AREA_SC"]) *100
                WAsum = feature["WA_sum"]
            else:
                calcPWA = 0
                WAsum = 0
            if feature["FA_sum"] != None:
                calcFS = (feature["FA_sum"] / feature["AREA_SC"]) *100
                FAsum = feature["FA_sum"]
            else:
                calcFS = 0
                FAsum = 0
            if feature["SA_sum"] != None:
                calcSS = (feature["SA_sum"] / feature["AREA_SC"]) *100
                SAsum = feature["SA_sum"] 
            else:
                calcSS = 0
                SAsum = 0
            attrs = {idxRND : calcRND, idxPWA : calcPWA, idxFS : calcFS, idxSS : calcSS, idxRN_Sum : RNsum, idxWA_Sum : WAsum, idxFA_Sum : FAsum, idxSA_Sum : SAsum}
            JoinCatchmentsSetttlementAreaSummarize.dataProvider().changeAttributeValues({feature.id() : attrs})
            
        #Calculation of precipitation
        feedback.setProgressText("\nCalculate precipitation")
        netcdf_dir = self.parameterAsString(parameters, self.precipitationData, context)
        # list of all .nc file in the directory
        netcdf_files = QDir(netcdf_dir).entryList(["*.nc"], QDir.Files)

        # Variables
        yearlyMeanRaster = None
        augustMeanRaster =  None
        firstRound=True
        firstFile=True

        spatref = None
        xres = None
        yres = None
        xmin = None
        xmax = None
        ymin = None
        ymax = None

        for filename in netcdf_files:
            i=1
            netcdf_file = os.path.join(netcdf_dir, filename)
            subdataset_path = 'NETCDF:"{}":pr'.format(netcdf_file)
            raster_layer_unc = QgsRasterLayer(subdataset_path, "Annual precipitation")
            rasterDataSource = gdal.Open(str(raster_layer_unc.source()))
            yearlyTemp = None
            if firstFile:
                spatref = raster_layer_unc.crs()
                xres = raster_layer_unc.rasterUnitsPerPixelX()
                yres = raster_layer_unc.rasterUnitsPerPixelY()
                ext = raster_layer_unc.extent()
                xmin = ext.xMinimum()
                xmax = ext.xMaximum()
                ymin = ext.yMinimum()
                ymax = ext.yMaximum()
            while i <= rasterDataSource.RasterCount:
                if i == 1:
                    yearlyTemp = np.array([rasterDataSource.GetRasterBand(i).ReadAsArray()])
                else:
                    yearlyTemp= np.append(yearlyTemp, [rasterDataSource.GetRasterBand(i).ReadAsArray()], axis=0)
                i+=1
                
            yearlyMean = np.sum(yearlyTemp, axis=0)
            augustMean = rasterDataSource.GetRasterBand(8).ReadAsArray()
            
            if firstRound:
                yearlyMeanRaster = np.array([yearlyMean])
                augustMeanRaster = np.array([augustMean])
                firstRound = False
            else:
                yearlyMeanRaster= np.append(yearlyMeanRaster, [yearlyMean], axis=0)
                augustMeanRaster= np.append(augustMeanRaster, [augustMean], axis=0)
            

        finalYearlyMeanRaster = np.mean(yearlyMeanRaster, axis=0)
        finalAugustMeanRaster = np.mean(augustMeanRaster, axis=0)

        outfnYearly = outputDir+catchmentSourceName+'_yearlyPrecipitation.tif'
        outfnAugust = outputDir+catchmentSourceName+'_augustPrecipitation.tif'
        self.createRaster(parameters, context, feedback, outfnYearly, xmax, xmin, xres, ymax, ymin, yres, spatref, finalYearlyMeanRaster)
        self.createRaster(parameters, context, feedback, outfnAugust, xmax, xmin, xres, ymax, ymin, yres, spatref, finalAugustMeanRaster)
        precipitationYearlyLayer = QgsRasterLayer(outfnYearly, "precipitationYearly")
        precipitationAugustLayer = QgsRasterLayer(outfnAugust, "precipitationAugust")
        processing.run("native:zonalstatistics",
            {'INPUT_RASTER': precipitationYearlyLayer,
             'RASTER_BAND':1,
             'INPUT_VECTOR': JoinCatchmentsSetttlementAreaSummarize,
             'COLUMN_PREFIX': "PreYearly_",
             'STATISTICS': [2]},
            context=context, feedback=feedback)
        
        finalLayer = processing.run("native:zonalstatisticsfb",
            {'INPUT_RASTER': precipitationAugustLayer,
             'RASTER_BAND':1,
             'INPUT': JoinCatchmentsSetttlementAreaSummarize,
             'COLUMN_PREFIX': "PreAugust_",
             'STATISTICS': [2],
             'OUTPUT': 'TEMPORARY_OUTPUT'},
            context=context, feedback=feedback)['OUTPUT']

        (sink, dest_id) = self.parameterAsSink(parameters, self.OUTPUT, context,
                                        finalLayer.fields(), finalLayer.wkbType(), finalLayer.sourceCrs())
        
        for feat in finalLayer.getFeatures():
            sink.addFeature(feat)
        
        

        """
        #Set progressbar
        features = catchmentAreaSource.getFeatures()
        total = 100.0 / catchmentAreaSource.featureCount() if catchmentAreaSource.featureCount() else 0
        for current, feature in enumerate(features):
            # Stop the algorithm if cancel button has been clicked
            if feedback.isCanceled():
                break
            # Update the progress bar
            feedback.setProgress(int(current * total))
        """
        return {self.OUTPUT: dest_id}
        

    def name(self):
        """
        Returns the algorithm name, used for identifying the algorithm. This
        string should be fixed for the algorithm, and must not be localised.
        The name should be unique within each provider. Names should contain
        lowercase alphanumeric characters only and no spaces or other
        formatting characters.
        """
        return 'Calculate geofactors'

    def displayName(self):
        """
        Returns the translated algorithm name, which should be used for any
        user-visible display of the algorithm name.
        """
        return self.tr(self.name())

    def group(self):
        """
        Returns the name of the group this algorithm belongs to. This string
        should be localised.
        """
        return self.tr(self.groupId())

    def groupId(self):
        """
        Returns the unique ID of the group this algorithm belongs to. This
        string should be fixed for the algorithm, and must not be localised.
        The group id should be unique within each provider. Group id should
        contain lowercase alphanumeric characters only and no spaces or other
        formatting characters.
        """
        return ''

    def tr(self, string):
        return QCoreApplication.translate('Processing', string)

    def createInstance(self):
        return CalculateGeofactors()


class CalculateContributingCatchments (QgsProcessingAlgorithm):
    """
    This is an example algorithm that takes a vector layer and
    creates a new identical one.

    It is meant to be used as an example of how to create your own
    algorithms and explain methods and variables used to do it. An
    algorithm like this will be available in all elements, and there
    is not need for additional work.

    All Processing algorithms should extend the QgsProcessingAlgorithm
    class.
    """

    # Constants used to refer to parameters and outputs. They will be
    # used when calling the algorithm from another algorithm, or when
    # calling from the QGIS console.

    OUTPUT = 'OUTPUT'
    catchmentAreas = 'CatchmentAreas'
    gaugingStations = 'GaugingStations'

    def initAlgorithm(self, config):
        """
        Here we define the inputs and output of the algorithm, along
        with some other properties.
        """

        self.addParameter(
            QgsProcessingParameterFeatureSource(
                self.catchmentAreas,
                self.tr('Catchment areas'),
                [QgsProcessing.TypeVectorPolygon]
            )
        )
        
        self.addParameter(
            QgsProcessingParameterFeatureSource(
                self.gaugingStations,
                self.tr('Gauging stations'),
                [QgsProcessing.TypeVectorPoint]
            )
        )


        # We add a feature sink in which to store our processed features (this
        # usually takes the form of a newly created vector layer when the
        # algorithm is run in QGIS).
        self.addParameter(
            QgsProcessingParameterFeatureSink(
                self.OUTPUT,
                self.tr('Output layer'),
                QgsProcessing.TypeVectorPolygon
            )
        )


    def processAlgorithm(self, parameters, context, feedback):
       # yearly average precipitation
        # define paths
        source = self.parameterAsSource(parameters, self.catchmentAreas, context)
        
        # process: intersection with subcatchments. Keep the "gbk_lawa" field in order to extract the contributing subcatchments in a later process
        gaug_result = processing.run("native:intersection", 
        {'INPUT':parameters[self.gaugingStations],
        'OVERLAY':parameters[self.catchmentAreas],
        'INPUT_FIELDS':[],
        'OVERLAY_FIELDS':['gbk_lawa'],
        'OVERLAY_FIELDS_PREFIX':'',
        'OUTPUT':'TEMPORARY_OUTPUT',
        'GRID_SIZE':None})

        # save temporary output
        gaug_gbk = gaug_result["OUTPUT"]
        
        (sink, dest_id) = self.parameterAsSink(parameters, self.OUTPUT, context,
                                               gaug_gbk.fields(), source.wkbType(), source.sourceCrs())

        # calculate contributing subcatchments for each gauging station
        # create an empty layer to store the result

        # extract fields from "gaug_gbk"
        fields = QgsFields()
        for field in gaug_gbk.fields():
            fields.append(field)


        # iterate over each gauging station
        for feature in gaug_gbk.getFeatures():
            # extract gbk_lawa from gauging station
            gbk = feature["gbk_lawa"]
            gbk_int_start = int(gbk)
            gbk_str_start = str(gbk_int_start)

            # check if the last four digits are all 9
            # I am doing this because some gbk_lawa code have errors so they need to be rounded up
            if gbk_str_start.endswith("9999"):
                gbk_int = gbk_int_start + 1
                gbk_str = str(gbk_int)
            else:
                gbk_str = gbk_str_start

            # calculate lower limit
            # Check if the first two digits are 96
            if gbk_str.startswith('96'):
                # Iterate over digits excluding the second digit if the first two digits are 96
                for i in range(len(gbk_str) - 1, 1, -1): # Start from the end, stop after the second character
                    if int(gbk_str[i]) % 2 == 0 and gbk_str[i] != '0':
                        min_gbk = gbk_str[:i+1] + '0' * (len(gbk_str) - i - 1)
                        break
            else:
                # Normal case
                for i in range(len(gbk_str) - 1, -1, -1):
                    if int(gbk_str[i]) % 2 == 0 and gbk_str[i] != '0':
                        min_gbk = gbk_str[:i+1] + '0' * (len(gbk_str) - i - 1)
                        break
            min_gbk = min(min_gbk,gbk_str_start)

            # calculate upper limit
            for i in range(len(gbk_str)-1, -1, -1):
                if gbk_str[i] !="0":
                    incremented_digit = int(gbk_str[:i+1]) + 1
                    max_gbk = str(incremented_digit) + '0' * (len(gbk_str) - i - 1)
                    break
            
            # extract subcatchments that match the gbk_lawa range
            contributing_result = processing.run("native:extractbyexpression", 
            {'INPUT':parameters[self.catchmentAreas],
            'EXPRESSION':f'"gbk_lawa">={min_gbk} AND "gbk_lawa"< {max_gbk}',
            'OUTPUT':'TEMPORARY_OUTPUT'})
            
            # save output layer
            contributing_catch = contributing_result["OUTPUT"]
            
            # calculate the dissolve layer in order to have one geometry containing
            # all the contributing subcatchments
            dissolved_result = processing.run("native:dissolve", 
            {'INPUT':contributing_catch,
            'FIELD':[],
            'SEPARATE_DISJOINT':False,
            'OUTPUT':'TEMPORARY_OUTPUT'})

            # save temporary output
            dissolved_layer = dissolved_result["OUTPUT"]
            
            
            
            # extract geometry from "dissolved"
            dissolved_feature = next(dissolved_layer.getFeatures())
            dissolved_geom = dissolved_feature.geometry()
            new_feature = QgsFeature(fields)
            new_feature.setGeometry(dissolved_geom)
            
            # copy features from gaug_gbk to new layer
            new_feature.setAttributes(feature.attributes())
            sink.addFeature(new_feature)

            

        # save the contributing layer to a new shapefile
        #output_path = self.parameterAsString(parameters, self.OUTPUT, context)
        #feedback.setProgressText(output_path)
        #result=QgsVectorFileWriter.writeAsVectorFormat(contributing_layer, output_path, "utf-8", contributing_layer.crs(),"ESRI Shapefile")

        # the output of this code is a polygon file containing the contributing subcatchments to each gauging station
        # within the Warnow catchment. These subcatchments are now "gauged subcatchments" because we have flow information related to them.

        # delete this line if not necessary
        # add it to the project
        #QgsProject.instance().addMapLayer(QgsVectorLayer(output_path, "contributing subcatchments","ogr"))
        


        return {self.OUTPUT: dest_id}

    def name(self):
        """
        Returns the algorithm name, used for identifying the algorithm. This
        string should be fixed for the algorithm, and must not be localised.
        The name should be unique within each provider. Names should contain
        lowercase alphanumeric characters only and no spaces or other
        formatting characters.
        """
        return 'Calculate contributing catchments '

    def displayName(self):
        """
        Returns the translated algorithm name, which should be used for any
        user-visible display of the algorithm name.
        """
        return self.tr(self.name())

    def group(self):
        """
        Returns the name of the group this algorithm belongs to. This string
        should be localised.
        """
        return self.tr(self.groupId())

    def groupId(self):
        """
        Returns the unique ID of the group this algorithm belongs to. This
        string should be fixed for the algorithm, and must not be localised.
        The group id should be unique within each provider. Group id should
        contain lowercase alphanumeric characters only and no spaces or other
        formatting characters.
        """
        return ''

    def tr(self, string):
        return QCoreApplication.translate('Processing', string)

    def createInstance(self):
        return CalculateContributingCatchments()
    
    
    
class CalculateFlow(QgsProcessingAlgorithm):
    """
    This is an example algorithm that takes a vector layer and
    creates a new identical one.

    It is meant to be used as an example of how to create your own
    algorithms and explain methods and variables used to do it. An
    algorithm like this will be available in all elements, and there
    is not need for additional work.

    All Processing algorithms should extend the QgsProcessingAlgorithm
    class.
    """

    # Constants used to refer to parameters and outputs. They will be
    # used when calling the algorithm from another algorithm, or when
    # calling from the QGIS console.

    OUTPUT = 'OUTPUT'
    gaugedSubcatchments = 'GaugedSubcatchments'
    ungaugedSubcatchments = 'UngaugedSubcatchments'

    def initAlgorithm(self, config):
        """
        Here we define the inputs and output of the algorithm, along
        with some other properties.
        """

        # We add the input vector features source. It can have any kind of
        # geometry.
        self.addParameter(
            QgsProcessingParameterFeatureSource(
                self.gaugedSubcatchments,
                self.tr('Gauged subcatchments'),
                [QgsProcessing.TypeVectorPolygon]
            )
        )
        
        self.addParameter(
            QgsProcessingParameterFeatureSource(
                self.ungaugedSubcatchments,
                self.tr('Ungauged subcatchments'),
                [QgsProcessing.TypeVectorPolygon]
            )
        )

        # We add a feature sink in which to store our processed features (this
        # usually takes the form of a newly created vector layer when the
        # algorithm is run in QGIS).
        self.addParameter(
            QgsProcessingParameterFeatureSink(
                self.OUTPUT,
                self.tr('Output layer')
            )
        )

    def processAlgorithm(self, parameters, context, feedback):
        """
        Here is where the processing itself takes place.
        """

        # Retrieve the feature source and sink. The 'dest_id' variable is used
        # to uniquely identify the feature sink, and must be included in the
        # dictionary returned by the processAlgorithm function.
        
         # First input data
        # At first, the model needs to be calibrated and validated so it will import data from the 
        # catchments containing the gauging stations (gauged subcatchments).
        # The file imported is a shapefile containing the geofactors previously calculated for each gauged subcatchment.
        # import data from gauged subcatchments 
        
         # Second input data
        # Another input of the model is the subcatchments where we are interested in estimating "Mean Flow" and 
        # "Mean Low Flow". These subcatchments are called "ungauged subcatchments", because we do not have flow information related to them 
        # This input is a polygon file containing the geofactors calculated for each subcatchment.
        # This input will be used later on, after the process of calibration and validation of the model with the gauged subcatchments.
        
        gaug_stat = self.parameterAsSource(parameters, self.gaugedSubcatchments, context)
        warnow_subcatch_gf = self.parameterAsSource(parameters, self.ungaugedSubcatchments, context)


        ##### FIRST PART OF THE MODEL
        # Selecting input (predictors) and output
        # In this part of the code, we select the number of predictors that will be used in the model and drop
        # the not necessaries columns. The predictors are the geofactors previously calculated. 
        # We also select the output and like we said before, there are 2 outputs of this model: "Mean Low Flow" and "Mean Flow". 
        # In this part of the code we select "Mean Flow" and in a second part we will estimate "Mean Low Flow". [not in this version of the script]

        # Get the field names
        # Get the field names
        field_names = [field.name() for field in gaug_stat.fields()]

        # extract attribute data from the layer
        features = gaug_stat.getFeatures()
        data = []

        for feature in features:
            # collect the attribute values for each feature
            data.append([feature[field] for field in field_names])
            
        # create dataframe
        gaug_stat_df = pd.DataFrame(data, columns = field_names)

    
        filterCol = ['H_median', 'H_stdev', 'H_min', 'AREA_SC', 'PERI_SC', 'PERI_SC', 'SHAPE_SC', 'S_median', 'S_stdev', 'RN_sum', 'WA_sum', 'FA_sum', 'SA_sum', 'RND', 'PWA', 'FS', 'SS', 'PreYearly_mean', 'PreAugust_mean']
        # select number of features (predictors) and dependent variable
        x = gaug_stat_df.filter(items=filterCol)
        
        y = gaug_stat_df["MQ"]

        ### Random Forest Regressor
        ##### Split the data for calibration (train) and validation (test)

        # prepare the data: divide into train and test set
        # scale the data
        scaler = StandardScaler()
        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)
        print(x_train)
        x_train = scaler.fit_transform(x_train) 
        x_test = scaler.transform(x_test)

        # Initialize the model
        # model initialization
        model = RandomForestRegressor()

        # model training
        model.fit(x_train,y_train)

        ##### Calibration
        # Here we work with the train dataset (x_train) to calibrate the model. 
        # After, we print the performance of the model through two metrics like RMSE and R^2.
        # I would like to print the metric of RMSE and Rsquared in the log messages panel of the plugin 
        # in order to give an idea of the performance of the model. [The metric is not part of the output]
        # If it is not possible, the "print" command can be deleted. 

        # performance of the trained model
        y_train_pred = model.predict(x_train)
        print("Calibration RMSE:", mean_squared_error(y_train, y_train_pred, squared=False))
        print("Calibration R-squared:", r2_score(y_train, y_train_pred))

        ##### Validation
        # Now, we work with the test dataset (x_test) to validate the model and make estimation on new different data. 
        # Like in the calibration, the performance of the model are evaluated by the metrics RMSE and R^2.

        # prediction and evaluation
        y_pred = model.predict(x_test)
        print("Validation RMSE:", mean_squared_error(y_test, y_pred, squared=False))
        print("Validation R-squared:", r2_score(y_test, y_pred))


        ##### SECOND PART OF THE MODEL
        ### Estimate flow in ungauged subcatchments
        # Now it is time to run the model with the ungauged subcatchments and make an estimation of "Mean Flow".
        # First, we select the predictors of the model (geofactors) and we drop all the other 
        # columns that are not necessaries.

        # Get the field names
        field_names = [field.name() for field in warnow_subcatch_gf.fields()]

        # extract attribute data from the layer
        features = warnow_subcatch_gf.getFeatures()
        data = []

        for feature in features:
            # collect the attribute values for each feature
            data.append([feature[field] for field in field_names])
            
        # create dataframe
        warnow_subcatch_gf_df = pd.DataFrame(data, columns = field_names)

        # select number of features (predictors) and dependent variable
        x_catch = warnow_subcatch_gf_df.filter(items=filterCol) #filter geofactors

        # scale the data
        x_catch = scaler.transform(x_catch)

        # Run the model to calculate "Mean Flow"
        # estimation of mean flow
        y_catch = model.predict(x_catch)

        # THIRD PART OF THE MODEL
        # The flow is estimated for each ungauged subcatchment and now it is time to store it in a new shapfile. 
        # The goal of this part of the code is to create a new polygon file with 2 columns(+ geometry): 
        # the gbk_lawa code of the ungauged subcatchment where the flow estimation was made,
        # the flow estimation + the geometry of the ungauged subcatchment.

        # create new dataframe
        output_df = pd.DataFrame({"gbk_lawa": warnow_subcatch_gf_df["gbk_lawa"],"MQ": y_catch})

        # create new shapefile     
        
        crs = warnow_subcatch_gf.sourceCrs()
        final_output = QgsVectorLayer("Polygon?crs={}".format(crs.authid()), "output test", "memory")
        final_output_provider = final_output.dataProvider()

        # start editing
        final_output.startEditing()

        # creation of my fields
        for head in output_df:
            myField = QgsField(head, QVariant.Double)
            final_output.addAttribute(myField)
            
        # update
        final_output.updateFields()

        # addition of features
        for row in output_df.itertuples():
            f = QgsFeature()
            f.setAttributes([row[1], row[2]])
            final_output.addFeature(f)
            
        # saving changes
        final_output.commitChanges()


        # create a new layer with MQ and gbk_lawa + geometry from warnow_subcatch        
        (sink, dest_id) = self.parameterAsSink(parameters, self.OUTPUT,
        context, final_output.fields(), warnow_subcatch_gf.wkbType(), warnow_subcatch_gf.sourceCrs())

        # iterate over each subcatchment
        for feature, subcatch_feature in zip(final_output.getFeatures(), warnow_subcatch_gf.getFeatures()):
        
            # extract geometry from the corresponding subcatchment feature
            subcatch_geom = subcatch_feature.geometry()
            
            # create a new feature with combined attributes and geometry
            new_feature = QgsFeature(final_output.fields())
            new_feature.setGeometry(subcatch_geom)

            # copy attributes from the final output
            new_feature.setAttributes(feature.attributes())
            
            # add the new feature to the contributing layer
            sink.addFeature(new_feature)


        # the output of this code is a polygon file containing the code of every ungauged subcatchment (gbk_lawa),
        # the estimated flow for each ungauged subcatchment (MQ) and the geometry of the relative ungauged subcatchment.
        return {self.OUTPUT: dest_id}

    def name(self):
        """
        Returns the algorithm name, used for identifying the algorithm. This
        string should be fixed for the algorithm, and must not be localised.
        The name should be unique within each provider. Names should contain
        lowercase alphanumeric characters only and no spaces or other
        formatting characters.
        """
        return 'Calculate Flow (Model)'

    def displayName(self):
        """
        Returns the translated algorithm name, which should be used for any
        user-visible display of the algorithm name.
        """
        return self.tr(self.name())

    def group(self):
        """
        Returns the name of the group this algorithm belongs to. This string
        should be localised.
        """
        return self.tr(self.groupId())

    def groupId(self):
        """
        Returns the unique ID of the group this algorithm belongs to. This
        string should be fixed for the algorithm, and must not be localised.
        The group id should be unique within each provider. Group id should
        contain lowercase alphanumeric characters only and no spaces or other
        formatting characters.
        """
        return ''

    def tr(self, string):
        return QCoreApplication.translate('Processing', string)

    def createInstance(self):
        return CalculateFlow()
    
    
    
    