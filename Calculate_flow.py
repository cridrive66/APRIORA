# -*- coding: utf-8 -*-

"""
/***************************************************************************
 APRIORA
                                 A QGIS plugin
 Collection of APRIORA Plugins
 Generated by Plugin Builder: http://g-sherman.github.io/Qgis-Plugin-Builder/
                              -------------------
        begin                : 2024-06-13
        copyright            : (C) 2024 by Universität Rostock
        email                : cristiano.guidi2@uni-rostock.de
 ***************************************************************************/

/***************************************************************************
 *                                                                         *
 *   This program is free software; you can redistribute it and/or modify  *
 *   it under the terms of the GNU General Public License as published by  *
 *   the Free Software Foundation; either version 2 of the License, or     *
 *   (at your option) any later version.                                   *
 *                                                                         *
 ***************************************************************************/
"""

__author__ = 'Universität Rostock'
__date__ = '2024-06-13'
__copyright__ = '(C) 2024 by Universität Rostock'

# This will get replaced with a git SHA1 when you do a git archive

__revision__ = '$Format:%H$'

import processing
import pandas as pd
import numpy as np
from math import sqrt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from PyQt5.QtCore import QVariant
from qgis.PyQt.QtCore import QCoreApplication, Qt, QDir, QVariant
from qgis.core import (QgsProcessingAlgorithm,
                       QgsProcessing,
                       QgsProcessingException,
                       QgsFeature,
                       QgsField,
                       QgsFields,
                       QgsFeatureSink,
                       QgsProject,
                       QgsProcessingAlgorithm,
                       QgsProcessingParameterBoolean,
                       QgsProcessingParameterDefinition,
                       QgsProcessingParameterEnum,
                       QgsProcessingParameterFeatureSource,
                       QgsProcessingParameterFeatureSink,
                       QgsProcessingParameterField,
                       QgsProcessingParameterNumber,
                       QgsField,
                       QgsVectorLayer,
                       edit)

# libraries for hierarchical clustering
from scipy.stats import spearmanr
from scipy.cluster import hierarchy
from scipy.spatial.distance import squareform
from collections import defaultdict

class CalculateFlow(QgsProcessingAlgorithm):
    """
    This is an example algorithm that takes a vector layer and
    creates a new identical one.

    It is meant to be used as an example of how to create your own
    algorithms and explain methods and variables used to do it. An
    algorithm like this will be available in all elements, and there
    is not need for additional work.

    All Processing algorithms should extend the QgsProcessingAlgorithm
    class.
    """

    # Constants used to refer to parameters and outputs. They will be
    # used when calling the algorithm from another algorithm, or when
    # calling from the QGIS console.

    OUTPUT_catch = 'OUTPUT_catch'
    OUTPUT_river = "OUTPUT_river"
    gaugedSubcatchments = 'GaugedSubcatchments'
    ungaugedSubcatchments = 'UngaugedSubcatchments'
    riverNetwork = "RiverNetwork"
    selectedGeofactors = "selected_geofactors"
    threshold_user = "threshold"
    adjusted = 'adjusted'
    # INPUT_FIELD_ID = 'INPUT_FIELD_ID'
    # INPUT_FIELD_NEXT = 'INPUT_FIELD_NEXT'
    # INPUT_FIELD_PREV = 'INPUT_FIELD_PREV'

    def shortHelpString(self):
        return self.tr(""" This tool estimates the flow for each subcatchment (Subcatchment level) or for each river section (River level).
        Workflow:
        1. Insert the gauged and ungauged subcatchments with geofactors calculated with the 3rd tool.
        2. Insert the river network calculated with the 1st tool.
        3 Click on "Run"
        """)

    def initAlgorithm(self, config):
        """
        Here we define the inputs and output of the algorithm, along
        with some other properties.
        """

        # We add the input vector features source. It can have any kind of
        # geometry.
        self.addParameter(
            QgsProcessingParameterFeatureSource(
                self.gaugedSubcatchments,
                self.tr('Gauged subcatchments with geofactors'),
                [QgsProcessing.TypeVectorPolygon]
            )
        )
        
        self.addParameter(
            QgsProcessingParameterFeatureSource(
                self.ungaugedSubcatchments,
                self.tr('Ungauged subcatchments with geofactors'),
                [QgsProcessing.TypeVectorPolygon]
            )
        )

        self.addParameter(
            QgsProcessingParameterFeatureSource(
                self.riverNetwork,
                self.tr('River network'),
                [QgsProcessing.TypeVectorLine]
            )
        )

        self.addParameter(
            QgsProcessingParameterBoolean(
                self.adjusted,
                self.tr('There are none or few gauging stations in the catchment'),
                defaultValue=False
            )
        )

        # define available geofactors
        self.geofactor_mapping = {
            'Medium Height': 'H_mean',
            'Height Standard Deviation': 'H_stdev',
            'Minimum Height': 'H_min',
            'Subcatchment Area': 'AREA_SC',
            'Subcatchment Perimeter': 'PERIM_SC',
            'Shape Factor': 'SHAPE_SC',
            'Mean Slope': 'Slp_mean',
            'Slope Standard Deviation': 'Slp_stdev',
            'River Network Density': 'RivNetDens',
            'Proportion of Water Area': 'PropWatAr',
            'Forest Share': 'Forest %',
            'Settlements Share': 'Settl %',
            'Yearly Precipitation Mean': 'PrecYearly',
            'August Precipitation Mean': 'PrecAugust'
        }
        self.geofactor_options = list(self.geofactor_mapping.keys())

        param_geofactors = QgsProcessingParameterEnum(
            self.selectedGeofactors,
            self.tr("Selected geofactors"),
            options = self.geofactor_options,
            defaultValue = list(range(len(self.geofactor_options))), # default is all the geofactors
            allowMultiple = True
        )
        
        param_threshold = QgsProcessingParameterNumber(
            self.threshold_user,
            self.tr('Collinearity Threshold'),
            type = QgsProcessingParameterNumber.Double,
            defaultValue = 0.5,
            minValue = 0.0,
            maxValue = 1.0,
            optional = False
        )

        #set it as advanced parameter
        param_geofactors.setFlags(param_geofactors.flags() | QgsProcessingParameterDefinition.FlagAdvanced)
        self.addParameter(param_geofactors)
        param_threshold.setFlags(param_threshold.flags() | QgsProcessingParameterDefinition.FlagAdvanced)
        self.addParameter(param_threshold)

        # self.addParameter(
        #     QgsProcessingParameterField(
        #         self.INPUT_FIELD_ID,
        #         self.tr("ID Field/NET_ID"),
        #         parentLayerParameterName = self.riverNetwork,
        #         type = QgsProcessingParameterField.Any,
        #         defaultValue = 'NET_ID'
        #     )
        # )
        
        # self.addParameter(
        #     QgsProcessingParameterField(
        #         self.INPUT_FIELD_PREV,
        #         self.tr("Prev Node Field/NET_FROM"),
        #         parentLayerParameterName = self.riverNetwork,
        #         type = QgsProcessingParameterField.Any,
        #         defaultValue = 'NET_FROM'
        #     )
        # )
        
        # self.addParameter(
        #     QgsProcessingParameterField(
        #         self.INPUT_FIELD_NEXT,
        #         self.tr("Next Node Field/NET_TO"),
        #         parentLayerParameterName = self.riverNetwork,
        #         type = QgsProcessingParameterField.Any,
        #         defaultValue = 'NET_TO'
        #     )
        # )
        
        # We add a feature sink in which to store our processed features (this
        # usually takes the form of a newly created vector layer when the
        # algorithm is run in QGIS).
        self.addParameter(
            QgsProcessingParameterFeatureSink(
                self.OUTPUT_catch,
                self.tr('Subcatchment level')
            )
        )

        self.addParameter(
            QgsProcessingParameterFeatureSink(
                self.OUTPUT_river,
                self.tr('River level')
            )
        )

    
    #def subcatchmentFlowEstimation(self, parameters, context, feedback, final_output, warnow_subcatch_gf, outputput_catch_key )

    def processAlgorithm(self, parameters, context, feedback):
        """
        Here is where the processing itself takes place.
        """

        # Retrieve the feature source and sink. The 'dest_id' variable is used
        # to uniquely identify the feature sink, and must be included in the
        # dictionary returned by the processAlgorithm function.
        
         # First input data
        # At first, the model needs to be calibrated and validated so it will import data from the 
        # catchments containing the gauging stations (gauged subcatchments).
        # The file imported is a shapefile containing the geofactors previously calculated for each gauged subcatchment.
        # import data from gauged subcatchments 
        
         # Second input data
        # Another input of the model is the subcatchments where we are interested in estimating "Mean Flow" and 
        # "Mean Low Flow". These subcatchments are called "ungauged subcatchments", because we do not have flow information related to them 
        # This input is a polygon file containing the geofactors calculated for each subcatchment.
        # This input will be used later on, after the process of calibration and validation of the model with the gauged subcatchments.
        
        gaug_stat = self.parameterAsSource(parameters, self.gaugedSubcatchments, context)
        #warnow_subcatch_gf = self.parameterAsSource(parameters, self.ungaugedSubcatchments, context)
        warnow_subcatch_layer = self.parameterAsVectorLayer(parameters, self.ungaugedSubcatchments, context)
        river_network = self.parameterAsSource(parameters, self.riverNetwork, context)
        selected_indices = self.parameterAsEnums(parameters, self.selectedGeofactors, context)
        selected_display_names = [self.geofactor_options[i] for i in selected_indices]
        selected_geofactors = [self.geofactor_mapping[name] for name in selected_display_names]     # convert display names to actual column names
        threshold_user = self.parameterAsDouble(parameters, self.threshold_user, context)
        river_layer_original = self.parameterAsVectorLayer(parameters, self.riverNetwork, context)
        
        # add "id_catch" to the subcatchment shapefile        
        field_name = "id_catch"
        fields = warnow_subcatch_layer.fields()

        # check if the field already exists
        if field_name not in [field.name() for field in fields]:
            feedback.reportError(f"No field {field_name} in the ungauged subcatchment file.")
            raise QgsProcessingException(f"Missing field: '{field_name}' in the ungauged subcatchment layer.")

        
        else:
            warnow_subcatch_gf = warnow_subcatch_layer
            feedback.pushInfo(f"\nField '{field_name}' exists.") 
        
        def flow_estimation(flow, final_output):
            ##### FIRST PART OF THE MODEL
            # Selecting input (predictors) and output
            # In this part of the code, we select the number of predictors that will be used in the model and drop
            # the not necessaries columns. The predictors are the geofactors previously calculated. 
            # We also select the output and like we said before, there are 2 outputs of this model: "Mean Low Flow" and "Mean Flow". 
            # In this part of the code we select "Mean Flow" and in a second part we will estimate "Mean Low Flow". [not in this version of the script]

            # Get the field names
            field_names = [field.name() for field in gaug_stat.fields()]

            # extract attribute data from the layer
            features = gaug_stat.getFeatures()
            data = []

            for feature in features:
                # collect the attribute values for each feature
                data.append([feature[field] for field in field_names])
                
            # create dataframe
            gaug_stat_df = pd.DataFrame(data, columns = field_names)

        
            # filterCol = ['H_mean', 'H_stdev', 'H_min', 'AREA_SC', 'PERIM_SC', 'SHAPE_SC', 'Slp_mean', 'Slp_stdev', 'RivNetDens', 'PropWatAr', 'Forest %', 'Settl %', 'PrecYearly', 'PrecAugust']
            # select number of features (predictors) and dependent variable
            x = gaug_stat_df.filter(items=selected_geofactors)
            feedback.setProgressText(f"\nDatabase columns: {x.columns} ")
            
            # # try to normalise the flow for the subcatchment area
            # y = gaug_stat_df["Mean Flow"]/gaug_stat_df["AREA_SC"].replace(0, np.nan) # avoid division by zero
            # feedback.setProgressText(f"\nFlow values normalised: {y} ")
            # y = StandardScaler().fit_transform(y.values.reshape(-1,1))

            y = gaug_stat_df[flow]/gaug_stat_df["AREA_SC"].replace(0, np.nan) # avoid division by zero


            """
            Remove multicollinearity between variables by performing hierarchical clustering on the Spearman rank-order correlations, picking a threshold,
            and keeping a single feature from each cluster.
            """
            def select_non_collinear_features(df, threshold):
                feedback.setProgressText(f"Collinearity threshold: {threshold}")
                # compute Spearman correlation matrix
                corr = spearmanr(df).correlation
                #corr = (corr + corr.T)/2    # ensure simmetry
                corr = np.maximum(corr, corr.T) # ensure simmetry
                np.fill_diagonal(corr,1)    # fill diagonal with ones

                # convert correlation matrix to a distance matrix
                distance_matrix = 1 - np.abs(corr)

                # force perfect symmetry again
                distance_matrix = np.maximum(distance_matrix, distance_matrix.T)

                # replace NaNs with a large value (e.g. 1.0, meaning maximum distance)
                distance_matrix = np.nan_to_num(distance_matrix, nan = 1.0)

                #feedback.setProgressText(f"\nDistance Matrix: {distance_matrix}")
            
                # perform hierarchical clustering
                dist_linkage = hierarchy.ward(squareform(distance_matrix)) # ward clustering is grouping a lot of features together in the case of a small catchment
                #dist_linkage = hierarchy.linkage(squareform(distance_matrix), method = "single")
                #feedback.setProgressText(f"\nLinkage Matrix: {dist_linkage}")

                # cluster features based on threshold
                max_linkage_distance = np.max(dist_linkage[:, 2]) # get the max linkage distance
                adjusted_threshold = threshold * max_linkage_distance # scale the user threshold
                
                cluster_ids = hierarchy.fcluster(dist_linkage, adjusted_threshold, criterion = "distance")
                cluster_id_to_feature_ids = defaultdict(list)
                #feedback.setProgressText(f"\nCluster IDs: {cluster_ids}")

                for idx, cluster_id in enumerate(cluster_ids):
                    cluster_id_to_feature_ids[cluster_id].append(idx)

                # select one representative feature from each cluster
                # the number inside v[x] means which feature is going to be selected
                selected_features = [v[0] for v in cluster_id_to_feature_ids.values()]
                selected_features_names = df.columns[selected_features]

                # return new dataframe with selected features
                return df[selected_features_names]
            
            # remove multicollinearity features
            x_nc = select_non_collinear_features(x, threshold = threshold_user)

            feedback.setProgressText(f"\nMulticollinearity features removed, this is the new database: {x_nc.columns} ")
            
            
            ### Random Forest Regressor
            ##### Split the data for calibration (train) and validation (test)

            # prepare the data: divide into train and test set
            # scale the data
            scaler = StandardScaler()
            x_train, x_test, y_train, y_test = train_test_split(x_nc, y, test_size=0.2, random_state=42)
            x_train = scaler.fit_transform(x_train) 
            x_test = scaler.transform(x_test)

            # Initialize the model
            # model initialization
            model = RandomForestRegressor()

            # model training
            model.fit(x_train,y_train)

            ##### Calibration
            # Here we work with the train dataset (x_train) to calibrate the model. 
            # After, we print the performance of the model through two metrics like RMSE and R^2.
            # I would like to print the metric of RMSE and Rsquared in the log messages panel of the plugin 
            # in order to give an idea of the performance of the model. [The metric is not part of the output]
            # If it is not possible, the "print" command can be deleted. 

            # performance of the trained model
            y_train_pred = model.predict(x_train)
            # get the matching areas for y_train by preserving index
            train_idx = y_train.index
            area_train = gaug_stat_df.loc[train_idx, "AREA_SC"]
    
            # convert normalized flows back to total flows
            y_train_total = y_train * area_train
            y_train_pred_total = y_train_pred * area_train
    
            # evaluation
            mse = mean_squared_error(y_train_total, y_train_pred_total)
            rmse = sqrt(mse)
            r2 = r2_score(y_train_total, y_train_pred_total)
            feedback.setProgressText(f"\nCalibration {flow} RMSE: {rmse}")
            feedback.setProgressText(f"Calibration {flow} R-squared: {r2}")
            # print("Calibration RMSE:", mean_squared_error(y_train, y_train_pred, squared=False))
            # print("Calibration R-squared:", r2_score(y_train, y_train_pred))

            ##### Validation
            # Now, we work with the test dataset (x_test) to validate the model and make estimation on new different data. 
            # Like in the calibration, the performance of the model are evaluated by the metrics RMSE and R^2.

            # prediction and evaluation
            y_pred = model.predict(x_test)
            # get the matching areas for y_train by preserving index
            test_idx = y_test.index
            area_test = gaug_stat_df.loc[test_idx, "AREA_SC"]
    
            # convert normalized flows back to total flows
            y_test_total = y_test * area_test
            y_pred_total = y_pred * area_test
    
            # evaluation
            mse = mean_squared_error(y_test_total, y_pred_total)
            rmse = sqrt(mse)
            r2 = r2_score(y_test_total, y_pred_total)
            feedback.setProgressText(f"\nValidation {flow} RMSE: {rmse}")
            feedback.setProgressText(f"Validation {flow} R-squared: {r2}\n")

            ##### SECOND PART OF THE MODEL
            ### Estimate flow in ungauged subcatchments
            # Now it is time to run the model with the ungauged subcatchments and make an estimation of "Mean Flow".
            # First, we select the predictors of the model (geofactors) and we drop all the other 
            # columns that are not necessaries.

            # Get the field names
            field_names = [field.name() for field in warnow_subcatch_gf.fields()]

            # extract attribute data from the layer
            features = warnow_subcatch_gf.getFeatures()
            data = []

            for feature in features:
                # collect the attribute values for each feature
                data.append([feature[field] for field in field_names])
                
            # create dataframe
            warnow_subcatch_gf_df = pd.DataFrame(data, columns = field_names)

            # select number of features (predictors) and dependent variable
            x_catch = warnow_subcatch_gf_df[x_nc.columns] #filter geofactors

            # scale the data
            x_catch = scaler.transform(x_catch)

            # Run the model to calculate "Mean Flow"
            # estimation of mean flow
            y_catch_normalized = model.predict(x_catch)
            y_catch = y_catch_normalized * warnow_subcatch_gf_df["AREA_SC"] # I need to put warnow_subcatch_gf_df and not x_catch because it can happen that the AREA_SC will not be use to make the prediction.

            # THIRD PART OF THE MODEL
            # The flow is estimated for each ungauged subcatchment and now it is time to store it in a new shapfile. 
            # The goal of this part of the code is to create a new polygon file with 2 columns(+ geometry): 
            # the gbk_lawa code of the ungauged subcatchment where the flow estimation was made,
            # the flow estimation + the geometry of the ungauged subcatchment.

            # create new dataframe
            output_df = pd.DataFrame({"id_catch": warnow_subcatch_gf_df["id_catch"].astype(int), flow: y_catch})

            # start editing
            final_output.startEditing()

            # add 'id_catch' if it does not exist
            existing_fields = [field.name() for field in final_output.fields()]

            if "id_catch" not in existing_fields:
                final_output.addAttribute(QgsField("id_catch", QVariant.Int))

            # add the new flow field
            if flow not in existing_fields:
                final_output.addAttribute(QgsField(flow, QVariant.Double))

            # # creation of my fields
            # for head in output_df.columns:
            #     # determine the column data type
            #     if head == "id_catch":
            #         field_type = QVariant.Int
            #     elif pd.api.types.is_integer_dtype(output_df[head]):
            #         field_type = QVariant.Int
            #     elif pd.api.types.is_numeric_dtype(output_df[head]):
            #         field_type = QVariant.Double
            #     elif pd.api.types.is_string_dtype(output_df[head]):
            #         field_type = QVariant.String
            #     else:
            #         field_type = QVariant.String # default to string for other types

            #     myField = QgsField(head, field_type)
            #     final_output.addAttribute(myField)
                
            # update
            final_output.updateFields()

            # builf a lookup table of existing features by id_catch
            existing_features = {f["id_catch"]: f for f in final_output.getFeatures()}
            
            # addition of features
            for row in output_df.itertuples():
                catch_id = getattr(row, "id_catch")
                flow_value = getattr(row, flow)

                if catch_id in existing_features:
                    # update existing features
                    feature = existing_features[catch_id]
                    feature.setAttribute(flow, flow_value)
                    final_output.updateFeature(feature)

                else:
                    # create new features
                    feature = QgsFeature(final_output.fields())
                    feature.setAttribute("id_catch", catch_id)
                    feature.setAttribute(flow, flow_value)
                    final_output.addFeature(feature)
                
            # saving changes
            final_output.commitChanges()

        # create new shapefile     
        crs = warnow_subcatch_gf.sourceCrs()
        final_output = QgsVectorLayer("Polygon?crs={}".format(crs.authid()), "output test", "memory")
        final_output_provider = final_output.dataProvider()

        flow_estimation("Mean_Flow", final_output)
        flow_estimation("M_Low_Flow", final_output)

        # # create a new layer with Mean Flow and gbk_lawa + geometry from warnow_subcatch        
        # (sink_catch, dest_id_catch) = self.parameterAsSink(parameters, self.OUTPUT_catch,
        # context, final_output.fields(), warnow_subcatch_gf.wkbType(), warnow_subcatch_gf.sourceCrs())

        # if sink_catch is None:
        #     raise QgsProcessingException(self.tr("Failed to create subcatchment sink"))

        # # iterate over each subcatchment
        # for feature, subcatch_feature in zip(final_output.getFeatures(), warnow_subcatch_gf.getFeatures()):
        
        #     # extract geometry from the corresponding subcatchment feature
        #     subcatch_geom = subcatch_feature.geometry()
            
        #     # create a new feature with combined attributes and geometry
        #     new_feature = QgsFeature(final_output.fields())
        #     new_feature.setGeometry(subcatch_geom)

        #     # copy attributes from the final output
        #     new_feature.setAttributes(feature.attributes())
            
        #     # add the new feature to the contributing layer
        #     sink_catch.addFeature(new_feature)


        """
        Distribute the estimated flow from subcatchment to river level
        """
        def distribute_flow_to_rivers(subcatch_layer, river_layer, flow_fields, id_field):
            """
            subcatch_layer: layer with subcatchment-level flows (mean flow and mean low flow)
            river_layer: layer with NET_ID, NET_TO and a id_field linking to subcatchment
            flow_fields: list of flow fields in subcatch_layer to distribute
            id_field: common linking field (e.g., 'id_catch')
            """

            # build dictionary: {id_catch: {flow_field: value}}
            flows_by_catch = {}
            for f in subcatch_layer.getFeatures():
                cid = f[id_field]
                flows_by_catch[cid] = {fld: f[fld] for fld in flow_fields}

            # add output fields to river layer if missing
            provider = river_layer.dataProvider()
            existing = [fld.name() for fld in river_layer.fields()]
            for fld in flow_fields:
                if fld not in existing:
                    provider.addAttributes([QgsField(fld, QVariant.Double)])
            river_layer.updateFields()

            # compute lengths per id_catch
            lengths = {}
            for feat in river_layer.getFeatures():
                cid = feat[id_field]
                if cid is None:
                    continue
                L = feat.geometry().length() or 0.0
                lengths.setdefault(cid, []).append((feat.id(), L))

            # distribute flows
            river_layer.startEditing()
            for cid, feats in lengths.items():
                total_len = sum(L for _, L in feats)
                if total_len <= 0:
                    continue
                if cid not in flows_by_catch:
                    continue

                for flow_field in flow_fields:
                    total_flow = flows_by_catch[cid][flow_field]
                    if total_flow is None:
                        continue

                    for fid, L in feats:
                        share = L / total_len
                        portion = float(total_flow) * share
                        f = river_layer.getFeature(fid)
                        f.setAttribute(flow_field, portion)
                        river_layer.updateFeature(f)

            river_layer.commitChanges()

        # create an independent copy of the river layer
        crs = river_layer_original.crs().authid()
        river_layer = QgsVectorLayer("LineString?crs={}".format(crs), "river_layer_copy", "memory")
        # copy attributes
        provider = river_layer.dataProvider()
        provider.addAttributes(river_layer_original.fields())
        river_layer.updateFields()
        # copy features
        feats = [f for f in river_layer_original.getFeatures()]
        provider.addFeatures(feats)


        # calculate flow distribution in river sections
        flow_fields = ["Mean_Flow", "M_Low_Flow"]
        distribute_flow_to_rivers(final_output, river_layer, flow_fields, id_field="id_catch")
        
        # """
        # The river network file can present multiple river sections within a subcatchment. 
        # Every river section needs to be associated with one subcatchment only and a subcatchment needs to be associated with one river section only.
        # """
        # # create a new layer, copy of the river network
        # river_copy = river_layer.clone()
        
        # # adding new fields in the river file
        # # add a troubleshooting line to check if these fields already exist or not
        # new_fields = [
        #     QgsField("CATCH_ID", QVariant.String),
        #     QgsField("CATCH_TO", QVariant.String),
        #     QgsField("CATCH_FROM", QVariant.String)
        # ]

        # with edit(river_copy):
        #     for field in new_fields:
        #         if river_copy.fields().indexFromName(field.name()) == -1:
        #             river_copy.addAttribute(field)
        #     river_copy.updateFields()

        # # create a mapping of id_riv to id_catch
        # river_to_catch = {feature["id_riv"]: feature["id_catch"] for feature in river_copy.getFeatures()}

        # # create a mapping of CATCH_ID to last CATCH_TO before transition
        # catch_to_mapping = {}

        # # update the river layer
        # with edit(river_copy):
        #     for river_feature in river_copy.getFeatures():
        #         fid = river_feature.id()
        #         net_id = river_feature["NET_ID"]
        #         net_to = river_feature["NET_TO"]
        #         id_catch = river_feature["id_catch"]

        #         # handle case where NET_TO is "Out"
        #         if net_to == "Out":
        #             catch_to = "Out"
        #         else:
        #             catch_to = river_to_catch.get(int(net_to), "Unknown") if net_to else "Unknown" #lookup id_catch of NET_TO

        #         # store the last valid CATCH_TO before transition
        #         if id_catch != catch_to and catch_to != "Out":
        #             catch_to_mapping[id_catch] = catch_to

        #         # assign values
        #         catch_id = id_catch
        #         catch_from = id_catch
                
        #         # update attributes
        #         river_copy.changeAttributeValue(fid, river_copy.fields().indexFromName("CATCH_ID"), catch_id)
        #         river_copy.changeAttributeValue(fid, river_copy.fields().indexFromName("CATCH_TO"), catch_to)
        #         river_copy.changeAttributeValue(fid, river_copy.fields().indexFromName("CATCH_FROM"), catch_from)
        
        # dissolve_output = processing.run("native:dissolve", {
        #     'INPUT': river_copy,
        #     'FIELD':['CATCH_ID'],
        #     'SEPARATE_DISJOINT':False,
        #     'OUTPUT':'TEMPORARY_OUTPUT'})["OUTPUT"]
        
        # # restore the correct CATCH_TO values after dissolving
        # with edit(dissolve_output):
        #     for feature in dissolve_output.getFeatures():
        #         catch_id = feature["CATCH_ID"]
        #         feature.setAttribute("CATCH_TO", catch_to_mapping.get(int(catch_id), "Out"))
        #         dissolve_output.updateFeature(feature)

        # # the output of this code is a polygon file containing the code of every ungauged subcatchment (gbk_lawa or another code),
        # # the estimated flow for each ungauged subcatchment (Mean Flow) and the geometry of the relative ungauged subcatchment.
        
        # # process to transfer the flow from a subcatchment level to a river level
        # join_output = processing.run("native:joinattributestable", 
        # {'INPUT':dissolve_output,
        # 'FIELD':'id_catch',
        # 'INPUT_2':final_output,
        # 'FIELD_2':'id_catch',
        # 'FIELDS_TO_COPY':['Mean_Flow', 'M_Low_Flow'],
        # 'METHOD':1,
        # 'DISCARD_NONMATCHING':False,
        # 'PREFIX':'',
        # 'OUTPUT':'TEMPORARY_OUTPUT'},
        # context=context, feedback=feedback)["OUTPUT"]

        # # check if join output contains features
        # if join_output.featureCount() == 0:
        #     feedback.pushWarning("Join resulted in an empty layer!")
        # else:
        #     feedback.pushInfo("Join completed successfully.")

        # QgsProject.instance().addMapLayer(river_layer)

        """
        Accumulate Mean Flow
        """

        '''loading the network'''
        #waternet = self.parameterAsVectorLayer(parameters, self.riverNetwork, context)
        # waternet = join_output
        waternet = river_layer

        '''names of fields for id,next segment, previous segment'''
        # id_field = "CATCH_ID"
        # next_field = "CATCH_TO"
        # prev_field = "CATCH_FROM"
        id_field = "NET_ID"
        next_field = "NET_TO"
        prev_field = "NET_FROM"
        calc_field = "Mean_Flow"
        
        '''field index for id,next segment, previous segment'''
        idxId = waternet.fields().indexFromName(id_field) 
        idxPrev = waternet.fields().indexFromName(prev_field)
        idxNext = waternet.fields().indexFromName(next_field)
        idxCalc = waternet.fields().indexFromName(calc_field)

        '''load data from layer "waternet" '''
        feedback.setProgressText(self.tr("Loading network layer\n "))
        Data = [[
            str(f.attribute(idxId)),
            str(f.attribute(idxPrev)),
            str(f.attribute(idxNext)),
            f.attribute(idxCalc),
            f.id()
        ] for f in waternet.getFeatures()]
        DataArr = np.array(Data, dtype='object')
        DataArr[np.where(DataArr[:,3] == None),3]=0
        feedback.setProgressText(self.tr("Data loaded \n Calculating flow paths \n"))

        '''segments with numbers'''
        calc_column = np.copy(DataArr[:,3])  # deep copy of column to do calculations on
        calc_segm = np.where(calc_column > 0)[0].tolist()  # indices!
        calc_segm = [i for i in calc_segm if (DataArr[i,1] != 'unconnected' and DataArr[i,2] != 'unconnected')]
        DataArr[:,3] = 0 # set all to 0

        '''function to find next features in the net'''
        def nextFtsCalc (MARKER2):
            vtx_to = DataArr[np.where(DataArr[:,0] == MARKER2)[0].tolist(),2][0] # "to"-vertex of actual segment
            rows_to = np.where(DataArr[:,1] == vtx_to)[0].tolist() # find rows in DataArr with matching "from"-vertices to vtx_to
            unconnected_errors = [DataArr[x, 4] for x in rows_to if DataArr[x, 2]=='unconnected']  # this can only happen after manual editing
            if len(unconnected_errors) > 0:
                waternet.removeSelection()
                waternet.selectByIds(unconnected_errors, waternet.SelectBehavior(1))
                raise QgsProcessingException(
                    'The selected features in the flow are marked as \'unconnected\' '
                    + '(most likely because of manual editing). Please delete the columns with the network information ('
                    + next_field
                    + ', '
                    + prev_field
                    + ') and run tool 1 \"Water Network Constructor\" again.'
                )
            return(rows_to)

        '''function to find flow path'''
        def FlowPath (Start_Row, fp_amount):
            MARKER=DataArr[Start_Row,0] #set MARKER to ID of the first segment
            Weg = [Start_Row]    
            i=0
            while i!=len(DataArr):
                next_rows = nextFtsCalc(MARKER)
                if len(next_rows) > 1: # deviding flow path
                    calc_column[StartRow] = 0
                    calc_column[next_rows] = calc_column[next_rows]+fp_amount/len(next_rows) # this can be changed to weightet separation later
                    out = [Weg, next_rows]
                    break
                if len(next_rows) == 1: # continuing flow path
                    Weg = Weg + next_rows
                    MARKER=DataArr[next_rows[0],0] # change MARKER to Id of next segment 
                if len(next_rows) == 0: # end point
                    out = [Weg]
                    break
                i=i+1
            return (out)

        total2 = len(calc_segm)
        while len(calc_segm) > 0:
            if feedback.isCanceled():
                break
            StartRow = calc_segm[0]
            amount = calc_column[StartRow] # amount to add to flow path
            calc_column[StartRow] = 0 #"delete" calculated amount from list (set 0)
            Fl_pth = FlowPath(StartRow, amount) # get flow path of StartRow 
            if len(Fl_pth)== 2:
                calc_segm = calc_segm + Fl_pth[1] # if flow path devides add new segments to calc_segm
            DataArr[Fl_pth[0],3] = DataArr[Fl_pth[0],3]+amount # Add the amount to the calculated flow path
            calc_segm = calc_segm[1:] # delete used segment
            calc_segm = list(set(calc_segm)) #delete duplicate values
            feedback.setProgress((1-(len(calc_segm)/total2))*100)

        '''add new field'''
        MQ_field_name = 'calc_'+calc_field
        waternet.dataProvider().addAttributes([QgsField(MQ_field_name, QVariant.Double)])
        waternet.updateFields()
        features = waternet.getFeatures()

        waternet.startEditing()
        # get the index of the new field in waternet
        field_idx = waternet.fields().indexOf(MQ_field_name)
        if field_idx == -1:
            feedback.reportError(f"Error: field {MQ_field_name} not found in waternet")

        for i, feature in enumerate(features):
            # Stop the algorithm if cancel button has been clicked
            if feedback.isCanceled():
                break
            # set the value for the new field
            value_to_set = float(DataArr[i, 3])
            #feedback.setProgressText(f"Setting feature {feature.id()} field {MQ_field_name} to {value_to_set}")

            # set the new field
            feature.setAttribute(field_idx, value_to_set)
            waternet.updateFeature(feature)
        waternet.commitChanges()

        """
        Accumulate Mean Low Flow
        """
        '''names of fields for id,next segment, previous segment'''
        calc_field = "M_Low_Flow"
        
        '''field index for id,next segment, previous segment'''
        idxCalc = waternet.fields().indexFromName(calc_field)

        '''load data from layer "waternet" '''
        feedback.setProgressText(self.tr("Loading network layer\n "))
        Data = []
        Data = [[
            str(f.attribute(idxId)),
            str(f.attribute(idxPrev)),
            str(f.attribute(idxNext)),
            f.attribute(idxCalc),
            f.id()
        ] for f in waternet.getFeatures()]
        DataArr = np.array(Data, dtype='object')
        DataArr[np.where(DataArr[:,3] == None),3]=0
        feedback.setProgressText(self.tr("Data loaded \n Calculating flow paths \n"))

        '''segments with numbers'''
        calc_column = np.copy(DataArr[:,3])  # deep copy of column to do calculations on
        calc_segm = np.where(calc_column > 0)[0].tolist()  # indices!
        calc_segm = [i for i in calc_segm if (DataArr[i,1] != 'unconnected' and DataArr[i,2] != 'unconnected')]
        DataArr[:,3] = 0 # set all to 0

        total2 = len(calc_segm)
        while len(calc_segm) > 0:
            if feedback.isCanceled():
                break
            StartRow = calc_segm[0]
            amount = calc_column[StartRow] # amount to add to flow path
            calc_column[StartRow] = 0 #"delete" calculated amount from list (set 0)
            Fl_pth = FlowPath(StartRow, amount) # get flow path of StartRow 
            if len(Fl_pth)== 2:
                calc_segm = calc_segm + Fl_pth[1] # if flow path devides add new segments to calc_segm
            DataArr[Fl_pth[0],3] = DataArr[Fl_pth[0],3]+amount # Add the amount to the calculated flow path
            calc_segm = calc_segm[1:] # delete used segment
            calc_segm = list(set(calc_segm)) #delete duplicate values
            feedback.setProgress((1-(len(calc_segm)/total2))*100)

        '''add new field'''
        MNQ_field_name = 'calc_'+calc_field
        waternet.dataProvider().addAttributes([QgsField(MNQ_field_name, QVariant.Double)])
        waternet.updateFields()
        features = waternet.getFeatures()

        waternet.startEditing()
        # get the index of the new field in waternet
        field_idx = waternet.fields().indexOf(MNQ_field_name)
        if field_idx == -1:
            feedback.reportError(f"Error: field {MNQ_field_name} not found in waternet")

        for i, feature in enumerate(features):
            # Stop the algorithm if cancel button has been clicked
            if feedback.isCanceled():
                break
            # set the value for the new field
            value_to_set = float(DataArr[i, 3])
            #feedback.setProgressText(f"Setting feature {feature.id()} field {MNQ_field_name} to {value_to_set}")

            # set the new field
            feature.setAttribute(field_idx, value_to_set)
            waternet.updateFeature(feature)
        waternet.commitChanges()


        #define new fields
        out_fields = QgsFields()
        wnet_fields = waternet.fields()
        #append fields
        for field in wnet_fields:
            out_fields.append(QgsField(field.name(), field.type()))

        #define new fields
        out_fields = QgsFields()
        wnet_fields = waternet.fields()
        #append fields
        for field in wnet_fields:
            out_fields.append(QgsField(field.name(), field.type()))
        
        # save the layer
        (sink_river, dest_id_river) = self.parameterAsSink(parameters, self.OUTPUT_river, context,
                                               out_fields, river_network.wkbType(), river_network.sourceCrs())
        
        if sink_river is None:
            raise QgsProcessingException(self.tr("Failed to create river sink"))
        
        # write features from out_fields to the sink
        
        for feature in waternet.getFeatures():
            # Stop the algorithm if cancel button has been clicked
            if feedback.isCanceled():
                break
            # Add a feature in the sink
            # outFt = QgsFeature()
            # outFt.setGeometry(feature.geometry())
            # outFt.setAttributes(feature.attributes())
            # outFt.setAttributes(feature.attributes()+[DataArr[i,3]])
            sink_river.addFeature(feature, QgsFeatureSink.FastInsert)
        
        del nextFtsCalc, FlowPath, DataArr
        
        # # add "calc_Mean Flow" to the subcatchment file
        # final_output_acc = processing.run("native:joinattributestable", {
        #     'INPUT': final_output,
        #     'FIELD':'id_catch',
        #     'INPUT_2':waternet,
        #     'FIELD_2':'id_catch',
        #     'FIELDS_TO_COPY':[MQ_field_name, MNQ_field_name],
        #     'METHOD':1,
        #     'DISCARD_NONMATCHING':False,
        #     'PREFIX':'',
        #     'OUTPUT':'TEMPORARY_OUTPUT'})["OUTPUT"]

        final_output_acc = final_output

        # create a new layer with Mean Flow and gbk_lawa + geometry from warnow_subcatch        
        (sink_catch, dest_id_catch) = self.parameterAsSink(parameters, self.OUTPUT_catch,
        context, final_output_acc.fields(), warnow_subcatch_gf.wkbType(), warnow_subcatch_gf.sourceCrs())

        if sink_catch is None:
            raise QgsProcessingException(self.tr("Failed to create subcatchment sink"))

        # iterate over each subcatchment
        for feature, subcatch_feature in zip(final_output_acc.getFeatures(), warnow_subcatch_gf.getFeatures()):
        
            # extract geometry from the corresponding subcatchment feature
            subcatch_geom = subcatch_feature.geometry()
            
            # create a new feature with combined attributes and geometry
            new_feature = QgsFeature(final_output_acc.fields())
            new_feature.setGeometry(subcatch_geom)

            # copy attributes from the final output
            new_feature.setAttributes(feature.attributes())
            
            # add the new feature to the contributing layer
            sink_catch.addFeature(new_feature)

       
        
        
        # return the result
        return {
            self.OUTPUT_catch: dest_id_catch,
            self.OUTPUT_river: dest_id_river
            }

        #return {}


    def name(self):
        """
        Returns the algorithm name, used for identifying the algorithm. This
        string should be fixed for the algorithm, and must not be localised.
        The name should be unique within each provider. Names should contain
        lowercase alphanumeric characters only and no spaces or other
        formatting characters.
        """
        return '4 - Flow estimation'

    def displayName(self):
        """
        Returns the translated algorithm name, which should be used for any
        user-visible display of the algorithm name.
        """
        return self.tr(self.name())

    def group(self):
        """
        Returns the name of the group this algorithm belongs to. This string
        should be localised.
        """
        return self.tr(self.groupId())

    def groupId(self):
        """
        Returns the unique ID of the group this algorithm belongs to. This
        string should be fixed for the algorithm, and must not be localised.
        The group id should be unique within each provider. Group id should
        contain lowercase alphanumeric characters only and no spaces or other
        formatting characters.
        """
        return 'Flow Estimation'

    def tr(self, string):
        return QCoreApplication.translate('Processing', string)

    def createInstance(self):
        return CalculateFlow()
    
